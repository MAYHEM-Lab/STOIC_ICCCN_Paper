Serverless computing is a promising new eventdriven
programming model that was designed by cloud vendors
to expedite the development and deployment of scalable web
services on cloud computing systems. Using the model, developers write applications that consist of simple, independent, stateless functions that the cloud invokes on-demand (i.e. elastically), in response to system-wide events (data arrival, messages, web requests, etc.).

In this work, we present STOIC (Serverless TeleOperable HybrId Cloud), an application scheduling and deployment system that extends the serverless model in three ways. First, STOIC adopts random sample consensus (RANSAC) and dynamic median window to precisely predict latency, based on which the scheduler dispatches image workloads across multiple cloud systems of a consistent serverless framework. Second, STOIC supports serverless function execution using hardware acceleration (e.g. GPU resources) when available from the underlying cloud system. Third, STOIC switches between selector and duplicator modes to address the instability of edge cloud clusters. 

We overview the design and implementation of STOIC and empirically evaluate it using real-world machine learning applications and multi-tier (e.g. edge-cloud) deployments. We find that STOIC's combined use of edge and cloud resources is able to outperform using either cloud in isolation and boost the system efficiency by selector and duplicator for the applications and datasets that we consider.

%Through our evaluation, STOIC outperforms single-runtime systems on real-world applications for IoT devices and edge cloud. In this paper, we present the design and implementation of STOIC, along with the empirical evaluation of its efficacy and performance for machine learning applications.

%simple  on the cloud for machine learning applications, considering the flexibility and elasticity it offers. However, the imbalance of computing resources between edge and public cloud dampens the availability and efficiency of serverless architecture, and consumes extraneous energy and costs from end-users. 
